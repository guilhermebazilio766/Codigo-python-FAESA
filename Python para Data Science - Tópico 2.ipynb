
Respondendo questões pendentes:¶
Q: É possível fixar inplace como sendo true?
R: A princípio, não. Veja este trecho do código fonte do Pandas. Vamos observar, por exemplo, o funcionamento da função reset_index: O código decide qual objeto alterar a partir da linha 1427, sendo que o valor desta vem do parâmetro opcional inplace fornecido na invocação, como podemos ver na linha 1417.
Q: É possível descobrir quais variáveis existem?
R: Sim! Temos as funções dir(), locals() e globals() que retornam as variáveis no escopo, as locais e as globais, respectivamente.
Q: O VS Code detecta variáveis que existem na memória mas não mais no script?
R: As funções dir(), locals() e globals() vêm do Python puro, e portanto, vão funcionar em qualquer lugar, seja no Jupyter, no terminal, em um arquivo .py editado em um editor de texto simples ou em uma IDE.
Criando DataFrames
Jeito 1: Fornecendo um dicionário
Cada chave é o nome de uma coluna
Cada valor é uma lista que forma uma coluna
In [427]:
import pandas as pd

df = pd.DataFrame({'Nome':['Adalberto','Bernardo','Carlos','Daniel','Ernesto'],
                   'Idade':[15,24,86,53,56],
                   'Peso':[50.5,80.3,75.3,64.2,68.9],
                   'Altura':[1.7,1.8,1.7,1.9,2.0]})

df
Out[427]:
Nome	Idade	Peso	Altura
0	Adalberto	15	50.5	1.7
1	Bernardo	24	80.3	1.8
2	Carlos	86	75.3	1.7
3	Daniel	53	64.2	1.9
4	Ernesto	56	68.9	2.0
In [428]:
df.shape
Out[428]:
(5, 4)
In [429]:
len(df)
Out[429]:
5
In [431]:
df.values
Out[431]:
array([['Adalberto', 15, 50.5, 1.7],
       ['Bernardo', 24, 80.3, 1.8],
       ['Carlos', 86, 75.3, 1.7],
       ['Daniel', 53, 64.2, 1.9],
       ['Ernesto', 56, 68.9, 2.0]], dtype=object)
In [432]:
type(df.values)
Out[432]:
numpy.ndarray
In [433]:
df.Idade.values
Out[433]:
array([15, 24, 86, 53, 56], dtype=int64)
In [271]:
df.Peso
Out[271]:
Adalberto    50.5
Bernardo     80.3
Carlos       75.3
Daniel       64.2
Ernesto      68.9
Fernanda      NaN
Name: Peso, dtype: float64
Fazendo comparação para obter resultado booleano e usando o resultado booleano como filtro
In [289]:
df.loc[(df.Peso > 70) & (df.Idade > 50)]
Out[289]:
Idade	Peso	Altura
Carlos	86.0	75.3	1.7
Modificando os rótulos de linha
Repare que, sem inplace=True, o objeto não seria modificado
In [253]:
df.set_index("Nome",inplace=True)
In [254]:
df
Out[254]:
Idade	Peso	Altura
Nome			
Adalberto	15	50.5	1.7
Bernardo	24	80.3	1.8
Carlos	86	75.3	1.7
Daniel	53	64.2	1.9
Ernesto	56	68.9	2.0
Obtendo os dados
Jeito 1: Usando os rótulos para obter dados através de loc
In [255]:
df.loc["Bernardo"]
Out[255]:
Idade     24.0
Peso      80.3
Altura     1.8
Name: Bernardo, dtype: float64
In [256]:
df.loc["Bernardo","Idade"]
Out[256]:
24
In [257]:
df.loc["Bernardo":"Daniel","Idade":"Peso"]
Out[257]:
Idade	Peso
Nome		
Bernardo	24	80.3
Carlos	86	75.3
Daniel	53	64.2
Criando DataFrames
Jeito 2: fornecer uma matriz, uma lista de rótulos de linha de uma lista de rótulos de colunas
Repare que as linhas da matriz representam linhas do DataFrame, enquanto no "jeito 1" as listas representavam colunas
Estou usando NumPy para transpor nossa matriz a fim de não fazer na mão
A matriz poderia ser do NumPy
In [262]:
import numpy as np

m = np.array([[15,24,86,53,56],
                   [50.5,80.3,75.3,64.2,68.9],
                   [1.7,1.8,1.7,1.9,2.0]])

m = m.transpose()

df = pd.DataFrame(m,
                 index=['Adalberto','Bernardo','Carlos','Daniel','Ernesto'],
                 columns=["Idade","Peso","Altura"])

df
Out[262]:
Idade	Peso	Altura
Adalberto	15.0	50.5	1.7
Bernardo	24.0	80.3	1.8
Carlos	86.0	75.3	1.7
Daniel	53.0	64.2	1.9
Ernesto	56.0	68.9	2.0
Obtendo dados
Jeito 2: usando o índice numérico da posição através de iloc
In [263]:
df.iloc[2,1]
Out[263]:
75.3
In [264]:
df.iloc[1:3,0:2]
Out[264]:
Idade	Peso
Bernardo	24.0	80.3
Carlos	86.0	75.3
Diferença extra entre loc e iloc:
Loc permite criação de novas linhas/colunas
In [265]:
df.loc["Fernanda","Idade"] = 30

df
Out[265]:
Idade	Peso	Altura
Adalberto	15.0	50.5	1.7
Bernardo	24.0	80.3	1.8
Carlos	86.0	75.3	1.7
Daniel	53.0	64.2	1.9
Ernesto	56.0	68.9	2.0
Fernanda	30.0	NaN	NaN
In [425]:
# O NaN é o not a number do numpy:
np.nan
Out[425]:
nan
Criando a linha toda de uma vez com loc
In [290]:
df.loc["Gabriel"] = [1,2,3]
Loc também cria coluna, mas só se setar um valor por vez
In [291]:
df.loc["Gabriel","UF"] = "ES"
In [292]:
df
Out[292]:
Idade	Peso	Altura	UF
Adalberto	15.0	50.5	1.7	NaN
Bernardo	24.0	80.3	1.8	NaN
Carlos	86.0	75.3	1.7	NaN
Daniel	53.0	64.2	1.9	NaN
Ernesto	56.0	68.9	2.0	NaN
Fernanda	30.0	NaN	NaN	NaN
Gabriel	1.0	2.0	3.0	ES
Podemos inserir a coluna inteira de uma vez com .insert
In [293]:
df.insert(4,"Cidade",["Marechal Floriano","Marechal Floriano","Marechal Floriano","Vitória","Vitória","Vitória","Domingos Martins"])
In [294]:
df
Out[294]:
Idade	Peso	Altura	UF	Cidade
Adalberto	15.0	50.5	1.7	NaN	Marechal Floriano
Bernardo	24.0	80.3	1.8	NaN	Marechal Floriano
Carlos	86.0	75.3	1.7	NaN	Marechal Floriano
Daniel	53.0	64.2	1.9	NaN	Vitória
Ernesto	56.0	68.9	2.0	NaN	Vitória
Fernanda	30.0	NaN	NaN	NaN	Vitória
Gabriel	1.0	2.0	3.0	ES	Domingos Martins
Obtendo apenas colunas numéricas para poder usar funções matemáticas sem medo de ser feliz:
In [297]:
df2 = df.iloc[:,:3]
In [299]:
df2.sum(axis=0)
Out[299]:
Idade     265.0
Peso      341.2
Altura     12.1
dtype: float64
In [300]:
df2.sum(axis=1)
Out[300]:
Adalberto     67.2
Bernardo     106.1
Carlos       163.0
Daniel       119.1
Ernesto      126.9
Fernanda      30.0
Gabriel        6.0
dtype: float64
In [301]:
df2.mean(axis=1)
Out[301]:
Adalberto    22.400000
Bernardo     35.366667
Carlos       54.333333
Daniel       39.700000
Ernesto      42.300000
Fernanda     30.000000
Gabriel       2.000000
dtype: float64
max não retorna uma linha, mas sim mistura linhas:
In [302]:
df2.max()
Out[302]:
Idade     86.0
Peso      80.3
Altura     3.0
dtype: float64
comparando com max e usando resultado booleano como filtro para obter uma linha concisa
In [304]:
df2.loc[df2.Peso == df2.Peso.max()]
Out[304]:
Idade	Peso	Altura
Bernardo	24.0	80.3	1.8
Visualizando apenas o começo
In [305]:
df.head(4)
Out[305]:
Idade	Peso	Altura	UF	Cidade
Adalberto	15.0	50.5	1.7	NaN	Marechal Floriano
Bernardo	24.0	80.3	1.8	NaN	Marechal Floriano
Carlos	86.0	75.3	1.7	NaN	Marechal Floriano
Daniel	53.0	64.2	1.9	NaN	Vitória
Visualizando apenas o final
In [306]:
df.tail(4)
Out[306]:
Idade	Peso	Altura	UF	Cidade
Daniel	53.0	64.2	1.9	NaN	Vitória
Ernesto	56.0	68.9	2.0	NaN	Vitória
Fernanda	30.0	NaN	NaN	NaN	Vitória
Gabriel	1.0	2.0	3.0	ES	Domingos Martins
Obtendo as 4 menores idades
In [310]:
df.sort_values(by="Idade").head(4)
Out[310]:
Idade	Peso	Altura	UF	Cidade
Gabriel	1.0	2.0	3.0	ES	Domingos Martins
Adalberto	15.0	50.5	1.7	NaN	Marechal Floriano
Bernardo	24.0	80.3	1.8	NaN	Marechal Floriano
Fernanda	30.0	NaN	NaN	NaN	Vitória
Obtendo as maiores idades
In [332]:
df.sort_values(by="Idade",ascending=False)
Out[332]:
Idade	Peso	Altura	UF	Cidade
Carlos	86.0	75.3	1.7	NaN	Marechal Floriano
Ernesto	56.0	68.9	2.0	NaN	Vitória
Daniel	53.0	64.2	1.9	NaN	Vitória
Fernanda	30.0	NaN	NaN	NaN	Vitória
Bernardo	24.0	80.3	1.8	NaN	Marechal Floriano
Adalberto	15.0	50.5	1.7	NaN	Marechal Floriano
Gabriel	1.0	2.0	3.0	ES	Domingos Martins
Podemos usar isso para detectar anomalias
Uma alternativa é o max:
In [311]:
df.max()
Out[311]:
Idade          86
Peso         80.3
Altura          3
Cidade    Vitória
dtype: object
Mudando número de linhas exibidas
In [315]:
# Reduza para ver a diferença
pd.options.display.max_rows = 10
df
Out[315]:
Idade	Peso	Altura	UF	Cidade
Adalberto	15.0	50.5	1.7	NaN	Marechal Floriano
Bernardo	24.0	80.3	1.8	NaN	Marechal Floriano
Carlos	86.0	75.3	1.7	NaN	Marechal Floriano
Daniel	53.0	64.2	1.9	NaN	Vitória
Ernesto	56.0	68.9	2.0	NaN	Vitória
Fernanda	30.0	NaN	NaN	NaN	Vitória
Gabriel	1.0	2.0	3.0	ES	Domingos Martins
Removendo coluna
In [318]:
df.drop("Altura",axis=1)
Out[318]:
Idade	Peso	UF	Cidade
Adalberto	15.0	50.5	NaN	Marechal Floriano
Bernardo	24.0	80.3	NaN	Marechal Floriano
Carlos	86.0	75.3	NaN	Marechal Floriano
Daniel	53.0	64.2	NaN	Vitória
Ernesto	56.0	68.9	NaN	Vitória
Fernanda	30.0	NaN	NaN	Vitória
Gabriel	1.0	2.0	ES	Domingos Martins
Fazendo soma sem obter NaN
In [322]:
df2.add(10,fill_value=0)
Out[322]:
Idade	Peso	Altura
Adalberto	25.0	60.5	11.7
Bernardo	34.0	90.3	11.8
Carlos	96.0	85.3	11.7
Daniel	63.0	74.2	11.9
Ernesto	66.0	78.9	12.0
Fernanda	40.0	10.0	10.0
Gabriel	11.0	12.0	13.0
In [323]:
df_a = df2.iloc[0:4]

df_a
Out[323]:
Idade	Peso	Altura
Adalberto	15.0	50.5	1.7
Bernardo	24.0	80.3	1.8
Carlos	86.0	75.3	1.7
Daniel	53.0	64.2	1.9
In [330]:
df_b = df2.tail(5)

df_b
Out[330]:
Idade	Peso	Altura
Carlos	86.0	75.3	1.7
Daniel	53.0	64.2	1.9
Ernesto	56.0	68.9	2.0
Fernanda	30.0	NaN	NaN
Gabriel	1.0	2.0	3.0
In [326]:
df_a.drop("UF",axis=1) + df_b
Out[326]:
Altura	Cidade	Idade	Peso	UF
Adalberto	NaN	NaN	NaN	NaN	NaN
Bernardo	NaN	NaN	NaN	NaN	NaN
Carlos	3.4	NaN	172.0	150.6	NaN
Daniel	3.8	NaN	106.0	128.4	NaN
Ernesto	NaN	NaN	NaN	NaN	NaN
Fernanda	NaN	NaN	NaN	NaN	NaN
Gabriel	NaN	NaN	NaN	NaN	NaN
In [331]:
df_a.add(df_b,fill_value=0)
Out[331]:
Idade	Peso	Altura
Adalberto	15.0	50.5	1.7
Bernardo	24.0	80.3	1.8
Carlos	172.0	150.6	3.4
Daniel	106.0	128.4	3.8
Ernesto	56.0	68.9	2.0
Fernanda	30.0	NaN	NaN
Gabriel	1.0	2.0	3.0
Métodos Estatísticos
In [333]:
df2.sum()
Out[333]:
Idade     265.0
Peso      341.2
Altura     12.1
dtype: float64
In [334]:
df2.sum(axis=1)
Out[334]:
Adalberto     67.2
Bernardo     106.1
Carlos       163.0
Daniel       119.1
Ernesto      126.9
Fernanda      30.0
Gabriel        6.0
dtype: float64
In [335]:
df2.cumsum()
Out[335]:
Idade	Peso	Altura
Adalberto	15.0	50.5	1.7
Bernardo	39.0	130.8	3.5
Carlos	125.0	206.1	5.2
Daniel	178.0	270.3	7.1
Ernesto	234.0	339.2	9.1
Fernanda	264.0	NaN	NaN
Gabriel	265.0	341.2	12.1
In [336]:
df.count()
Out[336]:
Idade     7
Peso      6
Altura    6
UF        1
Cidade    7
dtype: int64
In [337]:
df.max()
Out[337]:
Idade          86
Peso         80.3
Altura          3
Cidade    Vitória
dtype: object
In [340]:
df.describe().loc["count","Idade"]
Out[340]:
7.0
In [342]:
g = df.groupby("Cidade")
In [343]:
g.sum()
Out[343]:
Idade	Peso	Altura
Cidade			
Domingos Martins	1.0	2.0	3.0
Marechal Floriano	125.0	206.1	5.2
Vitória	139.0	133.1	3.9
In [344]:
g.mean()
Out[344]:
Idade	Peso	Altura
Cidade			
Domingos Martins	1.000000	2.00	3.000000
Marechal Floriano	41.666667	68.70	1.733333
Vitória	46.333333	66.55	1.950000
Lendo no disco
CSV
In [346]:
df3 = pd.read_csv("cases-brazil-cities-time.csv",sep=",")

df3
Out[346]:
epi_week	date	country	state	city	ibgeID	cod_RegiaoDeSaude	name_RegiaoDeSaude	newDeaths	deaths	newCases	totalCases	deaths_per_100k_inhabitants	totalCases_per_100k_inhabitants	deaths_by_totalCases	_source	last_info_date
0	9	2020-02-25	Brazil	SP	São Paulo/SP	3550308	35016.0	São Paulo	0	0	1	1	0.00000	0.00811	0.00000	SES	2021-05-24
1	9	2020-02-25	Brazil	TOTAL	TOTAL	0	NaN	NaN	0	0	1	1	0.00000	0.00047	0.00000	NaN	NaN
2	9	2020-02-26	Brazil	SP	São Paulo/SP	3550308	35016.0	São Paulo	0	0	0	1	0.00000	0.00811	0.00000	SES	2021-05-24
3	9	2020-02-26	Brazil	TOTAL	TOTAL	0	NaN	NaN	0	0	0	1	0.00000	0.00047	0.00000	NaN	NaN
4	9	2020-02-27	Brazil	SP	São Paulo/SP	3550308	35016.0	São Paulo	0	0	0	1	0.00000	0.00811	0.00000	SES	2021-05-24
...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
2131457	121	2021-05-26	Brazil	PR	Ângulo/PR	4101150	41015.0	15ª RS Maringá	0	6	0	283	204.77816	9658.70307	0.02120	SES	2021-05-26
2131458	121	2021-05-26	Brazil	BA	Érico Cardoso/BA	2900504	29003.0	Brumado	0	2	5	240	18.93939	2272.72727	0.00833	MS	2021-05-26
2131459	121	2021-05-26	Brazil	PA	Óbidos/PA	1505106	15002.0	Baixo Amazonas	0	116	0	6062	221.77188	11589.49260	0.01914	MS	2021-05-26
2131460	121	2021-05-26	Brazil	SP	Óleo/SP	3533809	35094.0	Ourinhos	0	1	1	71	40.46945	2873.33064	0.01408	MS	2021-05-26
2131461	121	2021-05-26	Brazil	TOTAL	TOTAL	0	NaN	NaN	2334	454768	75087	16280392	214.76070	7688.29015	0.02793	NaN	NaN
2131462 rows × 17 columns

Agrupamentos
In [347]:
df3.groupby("state")
Out[347]:
<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000001F4CCB1A490>
In [350]:
df4 = df3.groupby("state").sum()
In [352]:
df4.to_csv("soma_por_estado.csv")
Excel
In [353]:
df4.to_excel("soma_por_estado.xlsx",sheet_name="Aba 1")
In [354]:
df = pd.read_excel("soma_por_estado.xlsx",sheet_name = "Aba 1")
In [355]:
df
Out[355]:
state	epi_week	ibgeID	cod_RegiaoDeSaude	newDeaths	deaths	newCases	totalCases	deaths_per_100k_inhabitants	totalCases_per_100k_inhabitants	deaths_by_totalCases
0	AC	571606	10441859656	104406567	1653	297681	81853	14683162	5.102845e+05	3.647672e+07	139.38030
1	AL	2547988	106923184072	1067552596	4661	891012	190379	36708453	1.945994e+06	8.524004e+07	1574.31311
2	AM	1574765	32508873492	324662279	12943	2406643	383980	74494843	2.156820e+06	1.440802e+08	543.30396
3	AP	425155	10311196836	103099711	1674	325691	111097	22729337	3.873586e+05	5.686922e+07	66.28714
4	BA	10279272	464079779466	4615777919	20726	3225506	995364	163859066	5.790367e+06	3.651809e+08	3463.57588
...	...	...	...	...	...	...	...	...	...	...	...
23	SC	7281003	476517368203	4754890990	15006	1888572	956526	148412728	6.601104e+06	5.040826e+08	1935.46407
24	SE	1882643	82166100202	820637708	4981	864214	228827	38703150	2.212429e+06	8.715154e+07	1024.55679
25	SP	15964533	884629015192	8799236312	109241	17108550	3226875	512908354	1.614940e+07	6.406230e+08	8799.68720
26	TO	3438397	90086125830	895016228	2813	435380	175150	30034594	3.015635e+06	1.842559e+08	1171.95422
27	TOTAL	25701	0	0	454773	71340597	16280502	2607566145	3.369005e+04	1.231403e+06	14.94508
28 rows × 11 columns

SQL
pymysql

prompt do anaconda: conda install -c anaconda pymysql

In [356]:
import sqlalchemy as sqla

db = sqla.create_engine("mysql+pymysql://root@localhost/jpa_tutorial")

pd.read_sql("select * from teste",db)
Out[356]:
id	nome	sobrenome	idade	peso	altura	UF
0	1	Alberto	Gonçalves	25	92.3	1.76	ES
1	2	Bernardo	Miranda	52	76.5	1.65	SP
2	3	Carlos	Nascimento	24	84.1	1.79	RJ
3	4	Daniel	Vieira	65	81.7	1.90	MG
4	5	Ernesto	Lopes	44	79.6	1.82	BA
5	6	Fernanda	Ruas	13	55.2	1.52	MS
6	7	Gabriela	Botafogo	77	67.6	1.67	CE
7	8	Hiago	de Paula	42	75.2	1.80	AM
In [423]:
import requests

url = "https://api.github.com/repos/pandas-dev/pandas/issues"

resp = requests.get(url)

data = resp.json()

issues = pd.DataFrame(data)

issues
Out[423]:
url	repository_url	labels_url	comments_url	events_url	html_url	id	node_id	number	title	...	milestone	comments	created_at	updated_at	closed_at	author_association	active_lock_reason	pull_request	body	performed_via_github_app
0	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas...	https://github.com/pandas-dev/pandas/pull/42350	936086587	MDExOlB1bGxSZXF1ZXN0NjgyODk3NzUy	42350	BUG: Don't cache args during rolling/expanding...	...	{'url': 'https://api.github.com/repos/pandas-d...	0	2021-07-02T21:59:52Z	2021-07-02T22:01:02Z	None	MEMBER	None	{'url': 'https://api.github.com/repos/pandas-d...	- [x] closes #42287\r\n- [x] tests added / pas...	None
1	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas...	https://github.com/pandas-dev/pandas/issues/42349	936001052	MDU6SXNzdWU5MzYwMDEwNTI=	42349	API: pd.Label to disambiguate e.g. MultiIndex ...	...	None	1	2021-07-02T18:51:15Z	2021-07-02T19:11:53Z	None	MEMBER	None	NaN	The 'level' argument in MultiIndex methods can...	None
2	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas...	https://github.com/pandas-dev/pandas/issues/42347	935912349	MDU6SXNzdWU5MzU5MTIzNDk=	42347	RLS: Missing assets in release 1.3.0	...	None	3	2021-07-02T16:26:12Z	2021-07-02T17:43:03Z	None	CONTRIBUTOR	None	NaN	- [x] I have checked that this issue has not a...	None
3	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas...	https://github.com/pandas-dev/pandas/pull/42346	935882908	MDExOlB1bGxSZXF1ZXN0NjgyNzI0MTUx	42346	Rename index when using DataFrame.reset_index	...	None	0	2021-07-02T15:42:15Z	2021-07-02T15:42:49Z	None	NONE	None	{'url': 'https://api.github.com/repos/pandas-d...	- [x] closes #6878\r\n- [x] tests added / pass...	None
4	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas...	https://github.com/pandas-dev/pandas/issues/42345	935876620	MDU6SXNzdWU5MzU4NzY2MjA=	42345	BUG: regression for 1.3.0: saving a dataframe ...	...	None	0	2021-07-02T15:33:25Z	2021-07-02T15:37:42Z	None	CONTRIBUTOR	None	NaN	- [x] I have checked that this issue has not a...	None
...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
25	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas...	https://github.com/pandas-dev/pandas/pull/42304	932785286	MDExOlB1bGxSZXF1ZXN0NjgwMDg5NDk5	42304	DEPS: update setuptools min version	...	{'url': 'https://api.github.com/repos/pandas-d...	30	2021-06-29T14:51:46Z	2021-07-02T20:28:20Z	None	MEMBER	None	{'url': 'https://api.github.com/repos/pandas-d...	According to https://setuptools.readthedocs.io...	None
26	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas...	https://github.com/pandas-dev/pandas/issues/42303	932738401	MDU6SXNzdWU5MzI3Mzg0MDE=	42303	BUG: `__array_ufunc__` with for functions with...	...	None	0	2021-06-29T14:17:16Z	2021-06-29T14:17:16Z	None	CONTRIBUTOR	None	NaN	- [x] I have checked that this issue has not a...	None
27	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas...	https://github.com/pandas-dev/pandas/pull/42301	932653321	MDExOlB1bGxSZXF1ZXN0Njc5OTcyNDIx	42301	ENH: `Styler.bar` extended to allow centering ...	...	None	0	2021-06-29T13:14:18Z	2021-06-30T18:49:56Z	None	CONTRIBUTOR	None	{'url': 'https://api.github.com/repos/pandas-d...	This refactors `Styler.bar` to allow more flex...	None
28	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas...	https://github.com/pandas-dev/pandas/issues/42295	932388491	MDU6SXNzdWU5MzIzODg0OTE=	42295	BUG: df.where() inconsistently casts columns t...	...	None	0	2021-06-29T08:58:21Z	2021-06-30T07:15:43Z	None	NONE	None	NaN	- [x] I have checked that this issue has not a...	None
29	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas...	https://api.github.com/repos/pandas-dev/pandas...	https://github.com/pandas-dev/pandas/issues/42291	932150687	MDU6SXNzdWU5MzIxNTA2ODc=	42291	ENH: DataFrame.interpolate limit to support al...	...	None	1	2021-06-29T02:40:56Z	2021-07-02T11:53:38Z	None	NONE	None	NaN	Currently with `df.interpolate(limit, limit_di...	None
30 rows × 26 columns

Essas são as colunas
In [424]:
issues.columns
Out[424]:
Index(['url', 'repository_url', 'labels_url', 'comments_url', 'events_url',
       'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels',
       'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments',
       'created_at', 'updated_at', 'closed_at', 'author_association',
       'active_lock_reason', 'pull_request', 'body',
       'performed_via_github_app'],
      dtype='object')
Limpeza
Contando valores nulos em todo o df
In [368]:
df2.isnull().sum().sum()
Out[368]:
2
Mudando encoding do arquivo lido
Deveria dar erro mesmo nesse caso, pois não tinha um arquivo em mãos com um encoding diferente
In [370]:
pd.read_csv("cases-brazil-cities-time.csv",encoding="Windows-1252")
---------------------------------------------------------------------------
UnicodeDecodeError                        Traceback (most recent call last)
<ipython-input-370-fbc3c4dbe92e> in <module>
----> 1 pd.read_csv("cases-brazil-cities-time.csv",encoding="Windows-1252")

~\anaconda3\lib\site-packages\pandas\io\parsers.py in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)
    684     )
    685 
--> 686     return _read(filepath_or_buffer, kwds)
    687 
    688 

~\anaconda3\lib\site-packages\pandas\io\parsers.py in _read(filepath_or_buffer, kwds)
    450 
    451     # Create the parser.
--> 452     parser = TextFileReader(fp_or_buf, **kwds)
    453 
    454     if chunksize or iterator:

~\anaconda3\lib\site-packages\pandas\io\parsers.py in __init__(self, f, engine, **kwds)
    944             self.options["has_index_names"] = kwds["has_index_names"]
    945 
--> 946         self._make_engine(self.engine)
    947 
    948     def close(self):

~\anaconda3\lib\site-packages\pandas\io\parsers.py in _make_engine(self, engine)
   1176     def _make_engine(self, engine="c"):
   1177         if engine == "c":
-> 1178             self._engine = CParserWrapper(self.f, **self.options)
   1179         else:
   1180             if engine == "python":

~\anaconda3\lib\site-packages\pandas\io\parsers.py in __init__(self, src, **kwds)
   2006         kwds["usecols"] = self.usecols
   2007 
-> 2008         self._reader = parsers.TextReader(src, **kwds)
   2009         self.unnamed_cols = self._reader.unnamed_cols
   2010 

pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader.__cinit__()

pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader._get_header()

pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader._tokenize_rows()

pandas\_libs\parsers.pyx in pandas._libs.parsers.raise_parser_error()

UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 64510: character maps to <undefined>
Tratando nulos
In [372]:
df2.to_csv("file.csv")
In [376]:
teste = pd.read_csv("file.csv",na_values=["sn","s/n"])

teste
Out[376]:
Unnamed: 0	Idade	Peso	Altura
0	Adalberto	15.0	50.5	1.7
1	Bernardo	24.0	80.3	1.8
2	Carlos	86.0	75.3	1.7
3	Daniel	53.0	64.2	1.9
4	Ernesto	56.0	68.9	2.0
5	Fernanda	30.0	NaN	NaN
6	Gabriel	1.0	2.0	3.0
In [377]:
teste2 = pd.read_csv("file.csv")

teste2
Out[377]:
Unnamed: 0	Idade	Peso	Altura
0	Adalberto	15.0	50.5	1.7
1	Bernardo	24.0	80.3	1.8
2	Carlos	86.0	75.3	1.7
3	Daniel	53.0	64.2	1.9
4	Ernesto	56.0	68.9	2.0
5	Fernanda	30.0	sn	s/n
6	Gabriel	1.0	2.0	3.0
In [380]:
teste2.replace("sn",np.nan,inplace=True)
teste2.replace("s/n",np.nan,inplace=True)
teste2
Out[380]:
Unnamed: 0	Idade	Peso	Altura
0	Adalberto	15.0	50.5	1.7
1	Bernardo	24.0	80.3	1.8
2	Carlos	86.0	75.3	1.7
3	Daniel	53.0	64.2	1.9
4	Ernesto	56.0	68.9	2.0
5	Fernanda	30.0	NaN	NaN
6	Gabriel	1.0	2.0	3.0
Cabeçalho do CSV
In [383]:
teste2 = pd.read_csv("file.csv",header=1)

teste2
Out[383]:
Unnamed: 0	Idade	Peso	Altura
0	Adalberto	15.0	50.5	1.7
1	Bernardo	24.0	80.3	1.8
2	Carlos	86.0	75.3	1.7
3	Daniel	53.0	64.2	1.9
4	Ernesto	56.0	68.9	2.0
5	Fernanda	30.0	sn	s/n
6	Gabriel	1.0	2.0	3.0
Convertendo para dado numérico
In [385]:
teste2.set_index("Unnamed: 0",inplace=True)

teste2.loc["Gabriel"] = ["1","2","3"]

teste2
Out[385]:
Idade	Peso	Altura
Unnamed: 0			
Adalberto	15	50.5	1.7
Bernardo	24	80.3	1.8
Carlos	86	75.3	1.7
Daniel	53	64.2	1.9
Ernesto	56	68.9	2.0
Fernanda	30	sn	s/n
Gabriel	1	2	3
In [387]:
pd.to_numeric(teste2.loc["Gabriel"])
Out[387]:
Idade     1
Peso      2
Altura    3
Name: Gabriel, dtype: int64
Preenchendo nulos
In [389]:
df2.fillna(0)
Out[389]:
Idade	Peso	Altura
Adalberto	15.0	50.5	1.7
Bernardo	24.0	80.3	1.8
Carlos	86.0	75.3	1.7
Daniel	53.0	64.2	1.9
Ernesto	56.0	68.9	2.0
Fernanda	30.0	0.0	0.0
Gabriel	1.0	2.0	3.0
In [390]:
df2.median()
Out[390]:
Idade     30.00
Peso      66.55
Altura     1.85
dtype: float64
In [391]:
df2.Peso.fillna(df2.Peso.median())
Out[391]:
Adalberto    50.50
Bernardo     80.30
Carlos       75.30
Daniel       64.20
Ernesto      68.90
Fernanda     66.55
Gabriel       2.00
Name: Peso, dtype: float64
1 2 3 4 5 6 1_000_000

Concatenando dataframes
In [400]:
pd.concat([df1,df2],join="outer",axis=0)
Out[400]:
Idade	Peso	Altura
Adalberto	15.0	50.5	1.7
Bernardo	24.0	80.3	1.8
Carlos	86.0	75.3	1.7
Daniel	53.0	64.2	1.9
Adalberto	15.0	50.5	1.7
...	...	...	...
Carlos	86.0	75.3	1.7
Daniel	53.0	64.2	1.9
Ernesto	56.0	68.9	2.0
Fernanda	30.0	NaN	NaN
Gabriel	1.0	2.0	3.0
11 rows × 3 columns

In [401]:
pd.concat([df1,df2],join="outer",axis=1)
Out[401]:
Idade	Peso	Altura	Idade	Peso	Altura
Adalberto	15.0	50.5	1.7	15.0	50.5	1.7
Bernardo	24.0	80.3	1.8	24.0	80.3	1.8
Carlos	86.0	75.3	1.7	86.0	75.3	1.7
Daniel	53.0	64.2	1.9	53.0	64.2	1.9
Ernesto	NaN	NaN	NaN	56.0	68.9	2.0
Fernanda	NaN	NaN	NaN	30.0	NaN	NaN
Gabriel	NaN	NaN	NaN	1.0	2.0	3.0
In [402]:
pd.concat([df1,df2],join="inner",axis=1)
Out[402]:
Idade	Peso	Altura	Idade	Peso	Altura
Adalberto	15.0	50.5	1.7	15.0	50.5	1.7
Bernardo	24.0	80.3	1.8	24.0	80.3	1.8
Carlos	86.0	75.3	1.7	86.0	75.3	1.7
Daniel	53.0	64.2	1.9	53.0	64.2	1.9
In [408]:
df1.reset_index(inplace=True)
In [409]:
df2.reset_index(inplace=True)
In [412]:
df = pd.merge(df1,df2,on="index",how="outer")
In [413]:
df
Out[413]:
index	Idade_x	Peso_x	Altura_x	Idade_y	Peso_y	Altura_y
0	Adalberto	15.0	50.5	1.7	15.0	50.5	1.7
1	Bernardo	24.0	80.3	1.8	24.0	80.3	1.8
2	Carlos	86.0	75.3	1.7	86.0	75.3	1.7
3	Daniel	53.0	64.2	1.9	53.0	64.2	1.9
4	Ernesto	NaN	NaN	NaN	56.0	68.9	2.0
5	Fernanda	NaN	NaN	NaN	30.0	NaN	NaN
6	Gabriel	NaN	NaN	NaN	1.0	2.0	3.0
Alterando rótulos
In [415]:
df.rename({"index":"nomes","Idade_x":"idade"},axis=1)
Out[415]:
nomes	idade	Peso_x	Altura_x	Idade_y	Peso_y	Altura_y
0	Adalberto	15.0	50.5	1.7	15.0	50.5	1.7
1	Bernardo	24.0	80.3	1.8	24.0	80.3	1.8
2	Carlos	86.0	75.3	1.7	86.0	75.3	1.7
3	Daniel	53.0	64.2	1.9	53.0	64.2	1.9
4	Ernesto	NaN	NaN	NaN	56.0	68.9	2.0
5	Fernanda	NaN	NaN	NaN	30.0	NaN	NaN
6	Gabriel	NaN	NaN	NaN	1.0	2.0	3.0
In [416]:
df.rename({0:"Primeira pessoa",1:"Segunda pessoa"},axis=0)
Out[416]:
index	Idade_x	Peso_x	Altura_x	Idade_y	Peso_y	Altura_y
Primeira pessoa	Adalberto	15.0	50.5	1.7	15.0	50.5	1.7
Segunda pessoa	Bernardo	24.0	80.3	1.8	24.0	80.3	1.8
2	Carlos	86.0	75.3	1.7	86.0	75.3	1.7
3	Daniel	53.0	64.2	1.9	53.0	64.2	1.9
4	Ernesto	NaN	NaN	NaN	56.0	68.9	2.0
5	Fernanda	NaN	NaN	NaN	30.0	NaN	NaN
6	Gabriel	NaN	NaN	NaN	1.0	2.0	3.0
In [417]:
df.index
Out[417]:
Int64Index([0, 1, 2, 3, 4, 5, 6], dtype='int64')
In [418]:
df.describe()
Out[418]:
Idade_x	Peso_x	Altura_x	Idade_y	Peso_y	Altura_y
count	4.000000	4.000000	4.000000	7.000000	6.000000	6.000000
mean	44.500000	67.575000	1.775000	37.857143	56.866667	2.016667
std	32.067637	13.223054	0.095743	28.898838	28.769336	0.495648
min	15.000000	50.500000	1.700000	1.000000	2.000000	1.700000
25%	21.750000	60.775000	1.700000	19.500000	53.925000	1.725000
50%	38.500000	69.750000	1.750000	30.000000	66.550000	1.850000
75%	61.250000	76.550000	1.825000	54.500000	73.700000	1.975000
max	86.000000	80.300000	1.900000	86.000000	80.300000	3.000000
In [419]:
type(df)
Out[419]:
pandas.core.frame.DataFrame
In [421]:
type(df.values)
Out[421]:
numpy.ndarray
In [422]:
issues
Out[422]:
number	title	state
0	42350	BUG: Don't cache args during rolling/expanding...	open
1	42349	API: pd.Label to disambiguate e.g. MultiIndex ...	open
2	42347	RLS: Missing assets in release 1.3.0	open
3	42346	Rename index when using DataFrame.reset_index	open
4	42345	BUG: regression for 1.3.0: saving a dataframe ...	open
...	...	...	...
25	42304	DEPS: update setuptools min version	open
26	42303	BUG: `__array_ufunc__` with for functions with...	open
27	42301	ENH: `Styler.bar` extended to allow centering ...	open
28	42295	BUG: df.where() inconsistently casts columns t...	open
29	42291	ENH: DataFrame.interpolate limit to support al...	open
30 rows × 3 columns
